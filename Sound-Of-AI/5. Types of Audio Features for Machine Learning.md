### Why audio features?

- Description of sound (소리에 대한 묘사)
- Different features capture different aspects of sound (다양한 기능들이 소리의 다른 측면을 포착한다
- Build intelligent audio systems (지능형 오디오 시스템을 구축)

### Audio feature categorisation

#### Level of abstraction

소리의 high-level은 사람이 들을 수 있는 소리로 키, 멜로디, 리듬,템포 ,장르, 분위기가 있다.

소리의 mid-level로는 pitxh, MFCCS,beat,note가 있다.

소리의 low-level로는 진폭, 에너지, spectral centroid가 있다.

![image](https://github.com/meowmoeww/Audio/assets/89447043/bf4cee86-f994-46e4-828f-5766fc760f96)

#### Temporal scope (시간적인 측면)

Instantaneous (~50ms) : 소리가 순간적으로 발생하는 범위를 다룰 때 사용

Segment-level(seconds) : 여러 시간 단위의 세그먼트를 다룰 때 사용

Global : 전체적인 범위나 전반적인 시간 동안의 일을 의미

#### Music aspect (음악적인 측면)

Beat: 음악에서 박자는 시간적인 패턴으로, 음악의 리듬을 구성

Timbre:  음색으로서 음의 품질이나 소리의 특성을 의미합니다. 이는 악기나 보컬 등에서 발생하는 소리의 고유한 특성

Pitch: 음의 높낮이를 나타냅니다. 음악에서 높은 음고는 음이 높은 주파수를 갖고 있음을 나타내며, 낮은 음고는 낮은 주파수를 갖고 있다. 

Harmony : 서로 다른 음이 동시에 연주되는 것을 의미

#### Signal domain

**1) Time domain** 

우선 음성에서의 타임 도메인이 존재하는 이유 → 파형에서 값이 추출되기 때문이다. 기본적으로 파형은 소리에서 발생하는 모든 이벤트를 살펴볼 수 있고, 시간 도메인은 이 표현에서 정보를 추출하기 때문이다 

ex) Amplitude envelope, Root-mean square energy, Zero crossing rate

**2) Frequqncy domain**

 이는 raw audio 데이터를 다룰 때, 시간 영역에서 신호를 분석하는 것과 유사한 방식으로 신호를 분석한다.   푸리에 변환과 같은 기술을 적용하여 시간 도메인의 신호를 주파수 도메인으로 변환하여 주파수를 포함한 신호의 주요 특성을 감지하고 추출한다 . 

ex) Band energy ratio, Spectral centroid, Spectral flux 

**3) Time-frequency representation**

시간에 관련한 정보 + 주파수에 관련한 정보를 합친 표현이다

ex) Spectrogram, Mel-spectrogram, Constant-Q transform

![image](https://github.com/meowmoeww/Audio/assets/89447043/57999497-5d1f-4c2b-b5f3-5544014e6579)

위의 그래프는 x축은 시간이고 y축은 주파수에 관한 것으로, 시간과 주파수에 대한 정보를 모두 확인할 수 있다. 특정 시간에 각 주파수 대역이 갖는 기여도는 색상을 통해 설명된다. 

#### ML approach

1) Traditional machine learning

ex) Amplitude envelope, Zero crossing rate, Spectral flux

이 기법들은 오디오 파일에서 신호를 추출한 다음 Traditional ML algorithm의 입력 값으로 사용한다.

2) Deep learning

딥러닝은 오디오 파일에서 전체 스펙트로그램을 얻어내고 심층 신경망의 입력 값으로 사용한 다음 예측을 한다. 

- Types of intelligent audio systems

처음에는 DSP로 음성 신호를 처리하여 rule-based systems을 진행하고

그 다음으로는 Traditional ML을 사용하여 feature engineering을 진행하고 

마지막으로는 Deep learning을 사용하여 automatic feature extraction을 진행한다.

이제는 구조화되지 않은 스펙트로그램이나 실제 오디오를 입력값으로 사용하여, 딥러닝 알고리즘이 자동으로 특징을 추출할 수 있습니다.
