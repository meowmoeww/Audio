### 이전 시간에 다룬 ML을 위한 오디오 프로세싱에는 다음과 같은 세가지 방식이 있다.

1) Time-domain features

2) Frequency-domain features

3) Time-frequency domain features

## Time-domain feature pipeline

시간 도메인에서 time-domain feature를 얻어내기 위해서는, 아날로그 사운드를 샘플링하고 양자화 해야한다.

![image](https://github.com/meowmoeww/Audio/assets/89447043/07126d64-011b-4bc5-ad5c-70fea5be5946)

### Frames

•  프레임은 인지 가능한 오디오 데이터의 조각으로 오디오 신호를 작은 단위로 나눌 때 각각의 단위위다. 

하나의 샘플이 44.1KHz의 주파수를 가지고 있을 때, 하나의 샘플의 지속시간은 주파수의 역수인 0.0227ms와 같으며 이는 인간의 청각에 대한 시간분해능력의 임계값인 10ms보다 작다. 

이는 하나의 샘플은 독립적으로는 인지될 수 없으며 여러 샘플들이 모여서 의미 있는 오디오 정보를 형성한다는 걸 의미한다 .

• 프레임에 포함된 샘플의 수는 보통 2의 거듭제곱이며, 이는 컴퓨터 처리 효율성을 위한 것이다. 

•  프레임의 크기로 일반적으로 사용되는 샘플 수는 256개에서 8192개 사이이다.

d_f (프레임의 지속 시간) = 프레임 크기 (K) / 샘플링크기 (Sr) 

ex) 44100의 샘플을 가지게 만든 샘플링 크기로 512의 프레임 크기를 나누면 한 프레임의 지속 시간은 11.6ms가 나오게 된다.

![image](https://github.com/meowmoeww/Audio/assets/89447043/408afef9-cb7e-4b22-99d6-9b8ae2cb9189)

그런 다음 서로 다른 각각의 프레임의 시간 영역 특성을 계산하는 feature computation을 거친 후,

이러한 특성들을 요약하고 합치는 과정인 aggregation을 거치면  feature vaule/vector/matrix를 얻을 수 있다. 

aggregation 과정에서는  평균(mean), 중앙값(median), 가우시안 혼합 모델(Gaussian Mixture Model, GMM) 등 다양한 집계 방법을 사용할 수 있다.

## Frequency-domain feature pipiline

time domain에서 이루어진 프레이밍 과정까지는 동일하다.

## From time to frequency domain

![image](https://github.com/meowmoeww/Audio/assets/89447043/8e518f95-6701-4bb3-8f2f-c98478cc7faf)

그러나 여기서는 시간의 영역에서 주파수의 영역으로 변경시켜줘야한다. 

### spectral leackage

오디오 신호를 주파수 도메인으로 변환할 때 발생할 수 있는 문제점을 가리키는데, 특히 푸리에 변환 같은 주파수 분석을 할 때 나타날 수 있다. 

- 오디오 신호의 길이가 주기의 정수 배수가 아닐 경우, 분석 과정에서 실제로는 존재하지 않는 주파수 성분이 나타나는 왜곡 현상이 발생할 수 있다.
  
- 시간 도메인에서 신호를 잘라낼 때(예를 들어, 프레이밍을 할 때) 신호의 끝 부분이 다음 신호의 시작 부분과 부드럽게 연결되지 않으면, 주파수 도메인 변환 결과에 왜곡이 생길 수 있다.

![image](https://github.com/meowmoeww/Audio/assets/89447043/2685a2f4-4fdb-417d-9e99-90aa5dfab873)

- 신호 처리 중에 발생하는 불연속성(discontinuities)이 원래의 신호에는 없는 고주파 성분으로 나타나게 되고 이는 가짜 주파수 성분이 포함되어 실제 신호를 왜곡시키는 결과를 가진다.
아래 사진의 빨간색 박스를 보면, 원래 신호에는 존재하지 않지만 시간 표현을 주파수 표현으로 변경할 때 나타난 왜곡된 값이다.

![image](https://github.com/meowmoeww/Audio/assets/89447043/70eab096-1cd6-47fc-a52c-378934b02a48)

### windowing

스펙트럼 누출을 방지하기 위해 일반적으로 창 함수(window function)를 사용하여 신호의 끝을 부드럽게 하여, 이러한 불연속성을 최소화한다. 

![image](https://github.com/meowmoeww/Audio/assets/89447043/96f332ac-fc3d-449e-aa00-d443c61bbc91)

- 주파수 도메인 특징을 추출하기 전에 각 프레임에 대해 윈도우 함수를 적용하여 주변 데이터의 영향을 줄이는 것을 의미한다.
- 프레임의 끝점에 있는 샘플을 제거한다 → 시작과 끝에서 발생할 수 있는 불연속성이나 부드럽지 않은 절단 등의 문제를 완화할 수 있다.
- 윈도우 함수를 적용하면 일정한 주기를 갖는 주기적인 신호를 만들 수 있다.

![image](https://github.com/meowmoeww/Audio/assets/89447043/a8fe3997-e672-4872-8d3c-00092aa1749f)

원본 신호에 각 대응 샘플의 hand window를 곱해주는 것이다.

### 또 다른 문제 

![image](https://github.com/meowmoeww/Audio/assets/89447043/e5b44262-5a09-4991-b94f-a9e36a41d266)

Framing을 진행하다보면, 다음과 같이 분홍색 박스에 들어있는 신호들을 잃어버릴 수도 있다.

이를 잃어버리지 않기 위해서는 프레임을 겹치는 방법이 존재한다

### Non-overlapping frames

![image](https://github.com/meowmoeww/Audio/assets/89447043/ea69a874-811d-4ea0-8e39-1437bc0be0f6)

위의 사진과 같이 경우에는 겹치지 않게 프레임을 가진 것이다.

### Overlapping frames 

![image](https://github.com/meowmoeww/Audio/assets/89447043/e1fef166-b162-493d-9cfc-b1b42893163d)

오버래핑된 프레임들은 위의 사진과 같이 다음 프레임을 가질 때 전의 프레임에 겹치게끔 프레임을 설정하는 것이다. 

하나의 프레임의 크기는 Frame size라고 한다.

빨간색 박스의 왼쪽 선과, 초록색 박스의 왼쪽 선까지의 거리를 hop length라고 하며, 이는 연속적인 프레임 사이의 거리를 의미한다.

![image](https://github.com/meowmoeww/Audio/assets/89447043/3483848d-d47c-4a7a-9e93-a5846110661d)

Windowing까지 진행되고 나면, 스펙트럼 누출이 최소화된 스펙트럼을 가지게 되고 이후의 과정은 시간 영역 특징 파이프라인에서 사용한 것과 동일한 과정으로 진행이 된다.
