{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "import torchaudio\n",
    "from urbansounddataset import UrbanSoundDataset\n",
    "from cnn import CNNNetwork\n",
    "from main_train import AUDIO_DIR,ANNOTATIONS_FILE,SAMPLE_RATE,NUM_SAMPLES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4번 강의 코드 실행해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "annotations_file =  \"UrbanSound8K/UrbanSound8K/metadata/UrbanSound8K.csv\"\n",
    "audio_dir = \"UrbanSound8K/UrbanSound8K/audio\"\n",
    "\n",
    "\n",
    "SAMPLE_RATE=  22050 # 가지고 싶은 샘플 수를 결정 16000 -> 22050로 변경\n",
    "NUM_SAMPLES = 22050\n",
    "\n",
    "annotations = pd.read_csv(annotations_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slice_file_name</th>\n",
       "      <th>fsID</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>salience</th>\n",
       "      <th>fold</th>\n",
       "      <th>classID</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100032-3-0-0.wav</td>\n",
       "      <td>100032</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.317551</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100263-2-0-117.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>58.500000</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100263-2-0-121.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>60.500000</td>\n",
       "      <td>64.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100263-2-0-126.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100263-2-0-137.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>68.500000</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8727</th>\n",
       "      <td>99812-1-2-0.wav</td>\n",
       "      <td>99812</td>\n",
       "      <td>159.522205</td>\n",
       "      <td>163.522205</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>car_horn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8728</th>\n",
       "      <td>99812-1-3-0.wav</td>\n",
       "      <td>99812</td>\n",
       "      <td>181.142431</td>\n",
       "      <td>183.284976</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>car_horn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8729</th>\n",
       "      <td>99812-1-4-0.wav</td>\n",
       "      <td>99812</td>\n",
       "      <td>242.691902</td>\n",
       "      <td>246.197885</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>car_horn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8730</th>\n",
       "      <td>99812-1-5-0.wav</td>\n",
       "      <td>99812</td>\n",
       "      <td>253.209850</td>\n",
       "      <td>255.741948</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>car_horn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8731</th>\n",
       "      <td>99812-1-6-0.wav</td>\n",
       "      <td>99812</td>\n",
       "      <td>332.289233</td>\n",
       "      <td>334.821332</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>car_horn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8732 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         slice_file_name    fsID       start         end  salience  fold  \\\n",
       "0       100032-3-0-0.wav  100032    0.000000    0.317551         1     5   \n",
       "1     100263-2-0-117.wav  100263   58.500000   62.500000         1     5   \n",
       "2     100263-2-0-121.wav  100263   60.500000   64.500000         1     5   \n",
       "3     100263-2-0-126.wav  100263   63.000000   67.000000         1     5   \n",
       "4     100263-2-0-137.wav  100263   68.500000   72.500000         1     5   \n",
       "...                  ...     ...         ...         ...       ...   ...   \n",
       "8727     99812-1-2-0.wav   99812  159.522205  163.522205         2     7   \n",
       "8728     99812-1-3-0.wav   99812  181.142431  183.284976         2     7   \n",
       "8729     99812-1-4-0.wav   99812  242.691902  246.197885         2     7   \n",
       "8730     99812-1-5-0.wav   99812  253.209850  255.741948         2     7   \n",
       "8731     99812-1-6-0.wav   99812  332.289233  334.821332         2     7   \n",
       "\n",
       "      classID             class  \n",
       "0           3          dog_bark  \n",
       "1           2  children_playing  \n",
       "2           2  children_playing  \n",
       "3           2  children_playing  \n",
       "4           2  children_playing  \n",
       "...       ...               ...  \n",
       "8727        1          car_horn  \n",
       "8728        1          car_horn  \n",
       "8729        1          car_horn  \n",
       "8730        1          car_horn  \n",
       "8731        1          car_horn  \n",
       "\n",
       "[8732 rows x 8 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path: UrbanSound8K/UrbanSound8K/audio/fold5\\100032-3-0-0.wav\n",
      "\n",
      "tensor([[-4.5776e-03, -4.8828e-03, -4.6082e-03,  ..., -5.7983e-04,\n",
      "         -4.2725e-04,  3.0518e-05],\n",
      "        [-4.5166e-03, -4.7913e-03, -4.6082e-03,  ..., -7.3242e-04,\n",
      "         -5.4932e-04, -3.0518e-05]])\n",
      "\n",
      "44100\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "audio_dir = \"UrbanSound8K/UrbanSound8K/audio/\"\n",
    "fold = f\"fold{annotations.iloc[0,5]}\"\n",
    "path  = os.path.join(audio_dir,fold,annotations.iloc[0,0])\n",
    "signal,sr = torchaudio.load(path)\n",
    "print(\"path:\",path)\n",
    "print()\n",
    "print(signal)\n",
    "print()\n",
    "print(sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 강의 5번 실행해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signal tensor([[-4.5776e-03, -4.8828e-03, -4.6082e-03,  ..., -5.7983e-04,\n",
      "         -4.2725e-04,  3.0518e-05],\n",
      "        [-4.5166e-03, -4.7913e-03, -4.6082e-03,  ..., -7.3242e-04,\n",
      "         -5.4932e-04, -3.0518e-05]])\n",
      "\n",
      "size of signal torch.Size([2, 14004])\n",
      "\n",
      "sample_rate 44100\n"
     ]
    }
   ],
   "source": [
    "audio_dir = \"UrbanSound8K/UrbanSound8K/audio/\"\n",
    "index = 0\n",
    "fold = f\"fold{annotations.iloc[index,5]}\"\n",
    "path  = os.path.join(audio_dir,fold,annotations.iloc[index,0])\n",
    "signal,sr = torchaudio.load(path)\n",
    "print(\"signal\", signal)\n",
    "print()\n",
    "print(\"size of signal\", signal.size())\n",
    "print()\n",
    "print(\"sample_rate\",sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before  signal : tensor([[-4.5776e-03, -4.8828e-03, -4.6082e-03,  ..., -5.7983e-04,\n",
      "         -4.2725e-04,  3.0518e-05],\n",
      "        [-4.5166e-03, -4.7913e-03, -4.6082e-03,  ..., -7.3242e-04,\n",
      "         -5.4932e-04, -3.0518e-05]])\n",
      "\n",
      "after  signal : tensor([[-0.0031, -0.0051, -0.0048,  ..., -0.0036, -0.0025, -0.0008],\n",
      "        [-0.0031, -0.0051, -0.0046,  ..., -0.0036, -0.0026, -0.0010]])\n"
     ]
    }
   ],
   "source": [
    "target_sample_rate = 16000\n",
    "def _resample_if_necessary(signal,sr):\n",
    "# 모든 신호마다 샘플링 속도가 같은게 아니므로, 모두 같은 속도를 가질 수 있게 재샘플링을 진행해야 한다. \n",
    "    if sr != target_sample_rate:\n",
    "        resampler = torchaudio.transforms.Resample(sr,target_sample_rate)\n",
    "        signal = resampler(signal)\n",
    "    return signal\n",
    "\n",
    "print(f\"before  signal : {signal}\")\n",
    "print()\n",
    "after_signal = _resample_if_necessary(signal,sr)\n",
    "print(f\"after  signal : {after_signal}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 14004])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _mix_down_if_necessary( signal):\n",
    "         # 만약 신호의 채널이 1개가 아니라면 신호를 믹스다운 해준다.\n",
    "        if signal.shape[0] > 1: # (2,1000) 이럴 경우 \n",
    "            signal = torch.mean(signal,dim=0,keepdim=True)\n",
    "        return signal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before size of signal : torch.Size([2, 14004])\n",
      "\n",
      "after size of signal : torch.Size([1, 14004])\n"
     ]
    }
   ],
   "source": [
    "print(f\"before size of signal : {signal.size()}\")\n",
    "print()\n",
    "after_signal = _mix_down_if_necessary(signal)\n",
    "print(f\"after size of signal : {after_signal.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14004])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "torch.mean(signal,dim=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before signal : tensor([[-4.5776e-03, -4.8828e-03, -4.6082e-03,  ..., -5.7983e-04,\n",
      "         -4.2725e-04,  3.0518e-05],\n",
      "        [-4.5166e-03, -4.7913e-03, -4.6082e-03,  ..., -7.3242e-04,\n",
      "         -5.4932e-04, -3.0518e-05]])\n",
      "\n",
      "after signal : tensor([[[0.0054, 0.0013, 0.0026,  ..., 0.0041, 0.0022, 0.0010],\n",
      "         [0.0040, 0.0050, 0.0059,  ..., 0.0074, 0.0009, 0.0048],\n",
      "         [0.0019, 0.0037, 0.0215,  ..., 0.0049, 0.0019, 0.0066],\n",
      "         ...,\n",
      "         [0.0003, 0.0004, 0.0007,  ..., 0.0003, 0.0004, 0.0004],\n",
      "         [0.0003, 0.0003, 0.0005,  ..., 0.0004, 0.0005, 0.0004],\n",
      "         [0.0004, 0.0004, 0.0004,  ..., 0.0003, 0.0004, 0.0003]],\n",
      "\n",
      "        [[0.0048, 0.0009, 0.0028,  ..., 0.0041, 0.0020, 0.0012],\n",
      "         [0.0039, 0.0042, 0.0061,  ..., 0.0076, 0.0009, 0.0045],\n",
      "         [0.0024, 0.0044, 0.0205,  ..., 0.0050, 0.0020, 0.0060],\n",
      "         ...,\n",
      "         [0.0003, 0.0004, 0.0007,  ..., 0.0003, 0.0004, 0.0003],\n",
      "         [0.0003, 0.0003, 0.0005,  ..., 0.0004, 0.0005, 0.0004],\n",
      "         [0.0004, 0.0004, 0.0004,  ..., 0.0004, 0.0004, 0.0003]]])\n"
     ]
    }
   ],
   "source": [
    "mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n",
    "          sample_rate=SAMPLE_RATE,\n",
    "          n_fft=1024,\n",
    "          hop_length=512,\n",
    "          n_mels=64\n",
    "    )\n",
    "\n",
    "transformation = mel_spectrogram\n",
    "\n",
    "print(f\"before signal : {signal}\")\n",
    "print()\n",
    "after_signal = transformation(signal)\n",
    "print(f\"after signal : {after_signal}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before  signal : tensor([[-4.5776e-03, -4.8828e-03, -4.6082e-03,  ..., -5.7983e-04,\n",
      "         -4.2725e-04,  3.0518e-05],\n",
      "        [-4.5166e-03, -4.7913e-03, -4.6082e-03,  ..., -7.3242e-04,\n",
      "         -5.4932e-04, -3.0518e-05]])\n",
      "\n",
      "original sr: 44100\n",
      "target sr: 16000\n",
      "\n",
      "resampling : tensor([[-0.0032, -0.0051, -0.0048,  ..., -0.0032, -0.0020, -0.0005],\n",
      "        [-0.0031, -0.0051, -0.0047,  ..., -0.0032, -0.0021, -0.0006]])\n",
      "resampling + mix_down : tensor([[-0.0032, -0.0051, -0.0047,  ..., -0.0032, -0.0021, -0.0005]])\n",
      "resampling + mix_down + melspectrogram: tensor([[[2.7110e-04, 5.2016e-04, 6.6397e-05, 8.3281e-05, 4.7951e-05,\n",
      "          2.0758e-05, 3.4810e-05, 6.0773e-05, 3.2076e-05, 4.9419e-05],\n",
      "         [1.0270e-03, 9.5022e-04, 3.3454e-04, 4.4557e-03, 2.5491e-03,\n",
      "          7.3547e-04, 3.0474e-04, 3.2635e-04, 8.9394e-05, 3.1753e-04],\n",
      "         [1.1775e-03, 1.0801e-03, 2.0569e-03, 4.6966e-03, 3.1390e-03,\n",
      "          1.6138e-03, 1.3815e-03, 9.5162e-04, 8.4012e-04, 1.1672e-03],\n",
      "         [3.2479e-03, 5.0301e-03, 4.9103e-03, 6.7769e-03, 1.6375e-03,\n",
      "          1.2895e-03, 2.8536e-03, 2.7277e-03, 2.4066e-03, 3.2192e-03],\n",
      "         [6.5548e-04, 7.1318e-03, 5.3391e-03, 1.9845e-02, 6.1181e-04,\n",
      "          6.3585e-04, 1.2202e-03, 1.2230e-03, 2.2814e-03, 2.5599e-03],\n",
      "         [6.3775e-04, 2.5832e-03, 3.2982e-02, 5.1696e-02, 3.0760e-03,\n",
      "          3.5538e-03, 3.3610e-04, 3.3858e-04, 4.1456e-04, 1.2295e-03],\n",
      "         [1.7392e-03, 2.3402e-02, 1.1999e-01, 1.5677e-01, 2.7720e-02,\n",
      "          8.6143e-03, 1.2353e-03, 9.7777e-04, 1.4677e-03, 9.4808e-04],\n",
      "         [1.3489e-03, 6.5269e-02, 4.3957e-02, 7.7932e-02, 4.7708e-02,\n",
      "          8.7025e-03, 7.5928e-03, 2.5170e-03, 5.8222e-03, 2.1336e-03],\n",
      "         [1.2469e-03, 3.8040e-02, 1.0400e-02, 8.9597e-02, 3.2683e-02,\n",
      "          9.7823e-03, 1.0930e-02, 1.0318e-03, 2.9890e-03, 7.9884e-04],\n",
      "         [7.8162e-03, 1.3166e-02, 8.3040e-03, 1.4529e-02, 1.1575e-02,\n",
      "          7.4999e-03, 4.1138e-03, 8.7253e-04, 2.4933e-03, 5.8823e-04],\n",
      "         [4.2284e-03, 1.1444e-02, 1.6443e-02, 4.4963e-02, 2.5050e-02,\n",
      "          1.4880e-02, 1.6970e-03, 1.4014e-03, 2.5338e-03, 5.8933e-04],\n",
      "         [6.3378e-04, 3.1609e-02, 4.4616e-02, 3.0502e-02, 3.6808e-02,\n",
      "          6.5305e-03, 5.2067e-03, 1.9655e-03, 1.2973e-03, 3.9868e-04],\n",
      "         [1.8774e-03, 1.5512e-01, 7.3719e-02, 4.0618e-02, 1.9790e-02,\n",
      "          1.4075e-02, 7.2900e-03, 3.2916e-03, 1.5365e-03, 1.7999e-03],\n",
      "         [8.5768e-03, 2.9475e-01, 2.3984e-01, 7.3651e-02, 1.2834e-01,\n",
      "          2.5834e-02, 8.4747e-03, 5.2442e-03, 1.1556e-03, 1.7009e-03],\n",
      "         [3.9376e-02, 1.5842e-01, 1.8282e-01, 2.6595e-01, 6.2290e-02,\n",
      "          1.6880e-02, 6.6540e-03, 1.3056e-02, 2.6761e-03, 1.2943e-03],\n",
      "         [1.1348e+00, 6.5770e-01, 9.9433e-01, 1.0596e+00, 4.2720e-01,\n",
      "          5.0292e-02, 2.5006e-02, 1.0927e-02, 3.1966e-03, 1.3563e-03],\n",
      "         [8.5409e-01, 1.4906e+00, 2.2429e+01, 1.0524e+00, 1.0595e+00,\n",
      "          3.9717e-01, 1.8775e-02, 2.4302e-02, 3.7647e-03, 2.5797e-03],\n",
      "         [2.2977e-01, 4.8150e+00, 2.6432e+01, 6.7354e+00, 2.2258e+00,\n",
      "          7.9189e-01, 3.3826e-02, 4.8964e-02, 4.6541e-03, 4.7690e-03],\n",
      "         [2.8796e-01, 2.1442e+01, 4.0945e+01, 2.5410e+02, 5.0216e+01,\n",
      "          7.2946e+00, 4.1200e-01, 7.9495e-02, 1.3152e-01, 2.7995e-02],\n",
      "         [4.4597e-01, 1.7063e+01, 1.2515e+02, 3.9212e+02, 5.4438e+01,\n",
      "          6.8524e+00, 1.0192e+00, 1.7037e-01, 1.9507e-01, 5.8077e-02],\n",
      "         [2.7557e-01, 8.8801e+02, 3.2350e+02, 1.8855e+02, 3.1744e+01,\n",
      "          1.5457e+00, 6.7956e-01, 2.4815e-01, 9.2721e-02, 5.3392e-02],\n",
      "         [3.8408e-01, 3.8853e+03, 7.2651e+02, 1.0540e+03, 1.2578e+02,\n",
      "          4.4794e+00, 3.4074e+00, 1.1801e+00, 2.2598e-01, 1.0007e-01],\n",
      "         [1.1674e-01, 9.0292e+02, 1.3523e+03, 2.3080e+03, 3.8135e+02,\n",
      "          1.5981e+01, 1.2514e+01, 4.7397e+00, 8.2190e-01, 1.0915e-01],\n",
      "         [2.9568e-01, 1.5840e+02, 9.5875e+02, 4.3873e+02, 2.8366e+02,\n",
      "          3.4919e+01, 7.8539e+00, 2.9531e+00, 5.1507e-01, 1.6236e-01],\n",
      "         [2.3128e+00, 1.5902e+02, 8.3943e+02, 1.1501e+03, 4.5039e+02,\n",
      "          5.7417e+01, 1.6777e+01, 1.5846e+00, 2.9783e+00, 9.6830e-01],\n",
      "         [2.7471e+00, 5.8009e+01, 1.0252e+03, 1.5291e+03, 7.6743e+02,\n",
      "          1.3869e+02, 2.7331e+01, 1.9267e+00, 1.7440e+00, 4.3458e-01],\n",
      "         [2.7759e-01, 1.0742e+01, 3.6210e+02, 3.4614e+02, 7.6233e+02,\n",
      "          1.5302e+02, 3.1806e+01, 2.3067e+00, 7.2614e-01, 3.0865e-01],\n",
      "         [7.0485e-02, 6.0364e+00, 1.0325e+02, 8.7855e+01, 9.8244e+01,\n",
      "          1.0190e+02, 1.0917e+01, 9.7734e-01, 4.7245e-01, 1.8068e-01],\n",
      "         [6.8018e-02, 2.7748e+01, 7.4855e+01, 1.6882e+02, 4.9549e+01,\n",
      "          4.9351e+01, 4.6603e+00, 4.1772e-01, 1.8104e-01, 5.3929e-02],\n",
      "         [7.9482e-02, 1.0872e+01, 2.0697e+02, 7.3367e+02, 6.0239e+01,\n",
      "          3.1078e+01, 6.1284e+00, 1.4977e+00, 2.2307e-01, 8.7191e-02],\n",
      "         [2.4021e-01, 1.0412e+01, 4.7961e+01, 2.8124e+02, 1.0572e+02,\n",
      "          1.8814e+01, 4.0299e+00, 6.1913e-01, 2.2695e-01, 3.5535e-02],\n",
      "         [7.4589e-01, 8.6256e+01, 2.5768e+02, 6.2958e+02, 2.2050e+02,\n",
      "          1.7756e+01, 1.2728e+01, 4.1007e+00, 9.6217e-01, 1.0783e-01],\n",
      "         [6.0564e-01, 4.4624e+02, 1.9836e+03, 3.4441e+03, 7.8964e+02,\n",
      "          9.3857e+01, 4.1167e+01, 1.2090e+01, 3.6029e+00, 1.1624e+00],\n",
      "         [1.3707e-01, 1.8921e+02, 1.0639e+03, 3.8660e+03, 1.4406e+03,\n",
      "          1.4439e+02, 5.6419e+01, 9.7074e+00, 3.6175e+00, 1.2976e+00],\n",
      "         [2.7042e-02, 3.7081e+01, 2.3728e+02, 4.4600e+02, 2.0594e+02,\n",
      "          5.3073e+01, 5.8680e+00, 1.5304e+00, 2.6938e-01, 1.6940e-01],\n",
      "         [6.7175e-02, 1.2980e+01, 1.8050e+02, 3.6459e+02, 3.6984e+02,\n",
      "          1.9507e+01, 3.0228e+00, 7.3793e-01, 1.1494e-01, 1.2410e-01],\n",
      "         [1.4540e-01, 1.5794e+01, 1.3203e+02, 3.8128e+02, 1.3274e+02,\n",
      "          2.7868e+01, 1.0068e+01, 4.4526e-01, 3.9017e-01, 1.1594e-01],\n",
      "         [7.8595e-02, 1.1490e+01, 2.3998e+02, 7.2631e+02, 9.1997e+02,\n",
      "          2.7047e+01, 5.5783e+00, 2.9167e+00, 9.8720e-01, 1.3462e-01],\n",
      "         [1.8865e-02, 1.1774e+01, 6.8234e+02, 1.5909e+03, 1.2489e+03,\n",
      "          2.5751e+01, 9.4196e+00, 2.7823e+00, 5.9147e-01, 2.4478e-01],\n",
      "         [7.2613e-02, 5.7318e+01, 7.2263e+02, 8.2356e+02, 4.5915e+02,\n",
      "          1.2739e+01, 2.2219e+00, 1.1214e+00, 3.6013e-01, 9.1584e-02],\n",
      "         [5.6807e-01, 6.9747e+01, 3.3911e+02, 2.8292e+02, 1.9640e+02,\n",
      "          1.8416e+01, 1.9070e+00, 4.8963e-01, 2.1630e-01, 4.3874e-02],\n",
      "         [8.2164e-01, 3.0575e+01, 5.9369e+01, 7.4270e+01, 9.1820e+01,\n",
      "          6.8624e+00, 9.8279e-01, 2.9241e-01, 7.9804e-02, 2.7946e-02],\n",
      "         [4.0907e-02, 1.0138e+01, 6.5136e+01, 1.4455e+02, 9.2820e+01,\n",
      "          9.0418e+00, 1.3656e+00, 4.3536e-01, 6.6320e-02, 3.1902e-02],\n",
      "         [1.9268e-02, 8.1116e+00, 6.0023e+01, 1.0639e+02, 5.2652e+01,\n",
      "          5.5478e+00, 8.4274e-01, 1.3548e-01, 4.1997e-02, 1.8658e-02],\n",
      "         [8.6042e-02, 4.8171e+00, 1.8461e+01, 1.0723e+02, 1.6067e+01,\n",
      "          3.5753e+00, 8.4330e-01, 1.5333e-01, 8.5815e-02, 1.0131e-02],\n",
      "         [1.4293e-02, 7.9838e+00, 1.2903e+01, 7.8672e+01, 2.4442e+01,\n",
      "          1.5627e+00, 3.0754e-01, 8.7772e-02, 3.0357e-02, 8.4451e-03],\n",
      "         [5.9744e-03, 8.0312e+00, 9.5922e+00, 3.5140e+01, 1.3388e+01,\n",
      "          1.9876e+00, 2.5762e-01, 4.9117e-02, 1.8219e-02, 4.7146e-03],\n",
      "         [2.9009e-03, 1.1554e+00, 4.2323e+00, 1.9752e+01, 4.4791e+00,\n",
      "          8.1096e-01, 1.0542e-01, 4.7969e-02, 8.8348e-03, 2.8952e-03],\n",
      "         [8.5950e-04, 2.1602e-01, 2.3764e+00, 6.4173e+00, 3.2001e+00,\n",
      "          4.6341e-01, 1.0370e-01, 1.0665e-02, 9.2890e-03, 1.8331e-03],\n",
      "         [9.1729e-04, 2.3793e-01, 9.6011e-01, 2.9469e+00, 1.8397e+00,\n",
      "          3.9973e-01, 8.1223e-02, 1.2550e-02, 4.2981e-03, 1.3132e-03],\n",
      "         [9.0153e-03, 1.7635e+00, 2.6186e+00, 5.3141e+00, 1.7805e+00,\n",
      "          6.1124e+00, 3.3266e-01, 4.5245e-02, 1.1023e-02, 5.4950e-03],\n",
      "         [6.8844e-03, 5.2540e-01, 6.0459e+00, 6.8084e+00, 2.3726e+00,\n",
      "          1.0285e+01, 3.1676e-01, 8.0772e-02, 1.6751e-02, 8.6725e-03],\n",
      "         [6.5176e-03, 3.2392e-01, 2.3704e+00, 2.1492e+00, 5.5764e-01,\n",
      "          5.4074e-01, 5.3924e-02, 2.3822e-02, 3.0224e-03, 5.5454e-04],\n",
      "         [5.4571e-03, 1.6153e-01, 4.9338e-01, 1.8269e+00, 4.5428e-01,\n",
      "          2.0971e-01, 5.8484e-02, 5.5495e-03, 1.4329e-03, 5.2805e-04],\n",
      "         [4.6096e-04, 1.3381e-01, 1.6454e-01, 8.3452e-01, 4.7898e-01,\n",
      "          1.2367e-01, 2.1482e-02, 3.3892e-03, 1.2664e-03, 4.8327e-04],\n",
      "         [4.8246e-04, 6.1241e-02, 3.4822e-01, 9.7770e-01, 6.9682e-01,\n",
      "          1.1180e-01, 2.0659e-02, 4.1056e-03, 1.2802e-03, 2.9945e-04],\n",
      "         [2.3430e-04, 1.0116e-01, 3.5230e-01, 5.3303e-01, 1.1339e+00,\n",
      "          2.9063e-01, 4.1204e-02, 7.9564e-03, 1.5365e-03, 5.0412e-04],\n",
      "         [7.9199e-05, 4.7368e-02, 2.7920e-01, 1.2219e+00, 8.7022e-01,\n",
      "          2.3389e-01, 3.3541e-02, 6.7948e-03, 9.6991e-04, 3.7100e-04],\n",
      "         [7.2626e-05, 3.2855e-02, 5.1104e-01, 1.9497e+00, 1.1540e+00,\n",
      "          1.9197e-01, 3.3734e-02, 9.1662e-03, 8.4312e-04, 4.7833e-04],\n",
      "         [1.8315e-04, 2.3881e-02, 3.7733e-01, 9.4063e-01, 5.9640e-01,\n",
      "          9.8223e-02, 2.1081e-02, 4.9680e-03, 1.3585e-03, 3.9756e-04],\n",
      "         [1.3537e-04, 1.3956e-02, 3.7881e-01, 5.9554e-01, 3.9892e-01,\n",
      "          7.7240e-02, 1.6698e-02, 3.5376e-03, 8.4249e-04, 2.5265e-04],\n",
      "         [1.6149e-04, 1.7407e-02, 3.0137e-01, 3.5604e-01, 2.2815e-01,\n",
      "          6.1431e-02, 6.2165e-03, 1.2967e-03, 4.9779e-04, 1.3638e-04],\n",
      "         [2.5741e-04, 1.9126e-02, 2.7920e-01, 1.3917e+00, 9.1931e-01,\n",
      "          1.2032e-01, 1.8870e-02, 3.2002e-03, 6.2894e-04, 2.3443e-04],\n",
      "         [1.8432e-04, 3.7016e-02, 1.5777e+00, 5.8638e+00, 1.7206e+00,\n",
      "          1.9282e-01, 2.7205e-02, 7.5866e-03, 1.6660e-03, 3.9170e-04]]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"before  signal : {signal}\")\n",
    "print()\n",
    "after_signal = _resample_if_necessary(signal,sr)\n",
    "print(f\"resampling : {after_signal}\")\n",
    "after_signal2 = _mix_down_if_necessary(after_signal)\n",
    "print(f\"resampling + mix_down : {after_signal2}\")\n",
    "after_signal3 = transformation(after_signal2)\n",
    "print(f\"resampling + mix_down + melspectrogram: {after_signal3}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 강의 6번 진행하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before size of signal : torch.Size([2, 14004])\n",
      "\n",
      "after size of signal : torch.Size([2, 12000])\n"
     ]
    }
   ],
   "source": [
    "num_samples = 12000\n",
    "\n",
    "def _cut_if_necessary(signal):\n",
    "         # signal -> Tensor => (1, ) # (number of channel , num_samples)\n",
    "        if signal.shape[1] >num_samples:\n",
    "            signal = signal[:,:num_samples]\n",
    "        return signal \n",
    "\n",
    "print(f\"before size of signal : {signal.size()}\")\n",
    "print()\n",
    "after_signal = _cut_if_necessary(signal)\n",
    "print(f\"after size of signal : {after_signal.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 14004])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10803\n"
     ]
    }
   ],
   "source": [
    "audio_dir = \"UrbanSound8K/UrbanSound8K/audio/\"\n",
    "index = 875\n",
    "fold = f\"fold{annotations.iloc[index,5]}\"\n",
    "path  = os.path.join(audio_dir,fold,annotations.iloc[index,0])\n",
    "new_signal,sr = torchaudio.load(path)\n",
    "print(new_signal.size()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 12000\n",
    "\n",
    "def _right_pad_if_necessary(signal):\n",
    "        length_signal = signal.shape[1]\n",
    "        if length_signal < num_samples: # 신호에 있는 샘플 수가 예상되는 샘플 수보다 적을 때 \n",
    "            # [1,1,1] -> [1,1,1,0,0]\n",
    "            num_missing_samples = num_samples -  length_signal # 해당 신호가 예상하는 샘플 수가 있기 위해서 필요한 샘플의 수 \n",
    "            last_dim_padding = (0,num_missing_samples)\n",
    "            signal = torch.nn.functional.pad(signal,last_dim_padding) # 필요한 만큼 padding 해주기 \n",
    "        return signal  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10803"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11936"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_samples - after_signal3.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 8])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "after_signal3.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before  signal : tensor([[-0.0002, -0.0002, -0.0004,  ...,  0.0074,  0.0067,  0.0060],\n",
      "        [-0.0002, -0.0002, -0.0004,  ...,  0.0074,  0.0067,  0.0060]])\n",
      "size of before siganl : torch.Size([2, 10803]) \n",
      "after  signal : tensor([[-0.0002, -0.0002, -0.0002,  ...,  0.0000,  0.0000,  0.0000]])\n",
      "size of after siganl : torch.Size([1, 12000]) \n"
     ]
    }
   ],
   "source": [
    "print(f\"before  signal : {new_signal}\")\n",
    "print(f\"size of before siganl : {new_signal.size()} \")\n",
    "after_signal = _resample_if_necessary(new_signal,sr)\n",
    "after_signal2 = _mix_down_if_necessary(after_signal)\n",
    "num_missing_samples = num_samples - after_signal2.shape[1]\n",
    "last_dim_padding = (0,num_missing_samples)\n",
    "after_signal = torch.nn.functional.pad(after_signal2,last_dim_padding) \n",
    "\n",
    "print(f\"after  signal : {after_signal}\")\n",
    "print(f\"size of after siganl : {after_signal.size()} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 24])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fianl_signal = transformation(after_signal)\n",
    "print(fianl_signal.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 강의 8번 진행하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 44])\n"
     ]
    }
   ],
   "source": [
    "SAMPLE_RATE=  22050\n",
    "NUM_SAMPLES = 22050\n",
    "\n",
    "mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n",
    "          sample_rate=SAMPLE_RATE,\n",
    "          n_fft=1024,\n",
    "          hop_length=512,\n",
    "          n_mels=64\n",
    "    )\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = .001\n",
    "ANNOTATIONS_FILE =  \"UrbanSound8K/UrbanSound8K/metadata/UrbanSound8K.csv\"\n",
    "AUDIO_DIR = \"UrbanSound8K/UrbanSound8K/audio\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "else:\n",
    "        device = \"cpu\"\n",
    "\n",
    "    # ms = mel_spectrogram(siganl)\n",
    "usd = UrbanSoundDataset(ANNOTATIONS_FILE,\n",
    "                            AUDIO_DIR,\n",
    "                            mel_spectrogram, # 위에서 정의한 mel_spectrogram을 사용\n",
    "                            SAMPLE_RATE,\n",
    "                            NUM_SAMPLES,\n",
    "                            device)\n",
    "\n",
    "inputs, target = usd[0]\n",
    "print(inputs.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,\n",
    "                out_channels=16,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=2\n",
    "            ),\n",
    "\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=16,\n",
    "                out_channels=32,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=2\n",
    "            ),\n",
    "\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv3 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=32,\n",
    "                out_channels=64,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=2\n",
    "            ),\n",
    "\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv4 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=64,\n",
    "                out_channels=128,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=2\n",
    "            ),\n",
    "\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = nn.Flatten()\n",
    "linear = nn.Linear(128*5*4,10)\n",
    "softmax = nn.Softmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input data: torch.Size([1, 64, 44])\n",
      "the output of conv1  layer: torch.Size([16, 33, 23])\n",
      "the output of conv2 layer: torch.Size([32, 17, 12])\n",
      "the output of conv3 layer: torch.Size([64, 9, 7])\n",
      "the output of conv4 layer: torch.Size([128, 5, 4])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, 64, 44)\n",
    "print(f\"input data: {x.size()}\")\n",
    "x = conv1(x)\n",
    "print(f\"the output of conv1  layer: {x.size()}\")\n",
    "x = conv2(x)\n",
    "print(f\"the output of conv2 layer: {x.size()}\")\n",
    "x = conv3(x)\n",
    "print(f\"the output of conv3 layer: {x.size()}\")\n",
    "x = conv4(x)\n",
    "print(f\"the output of conv4 layer: {x.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the output of flatten layer: torch.Size([2560])\n",
      "the output of linear layer: torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x = x.view(-1)\n",
    "print(f\"the output of flatten layer: {x.size()}\")\n",
    "logits = linear(x)\n",
    "print(f\"the output of linear layer: {logits.size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 강의 10번 진행하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
